From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Dietmar Maurer <dietmar@proxmox.com>
Date: Fri, 17 Apr 2020 08:57:48 +0200
Subject: [PATCH] PVE Backup: use QemuMutex instead of QemuRecMutex

We acquire/release all mutexes outside coroutines now, so we can now
correctly use a normal mutex.
---
 pve-backup.c | 58 ++++++++++++++++++++++++++--------------------------
 1 file changed, 29 insertions(+), 29 deletions(-)

diff --git a/pve-backup.c b/pve-backup.c
index dddf430399..bb917ee972 100644
--- a/pve-backup.c
+++ b/pve-backup.c
@@ -31,7 +31,7 @@
 static struct PVEBackupState {
     struct {
         // Everithing accessed from qmp_backup_query command is protected using lock
-        QemuRecMutex lock;
+        QemuMutex lock;
         Error *error;
         time_t start_time;
         time_t end_time;
@@ -46,14 +46,14 @@ static struct PVEBackupState {
     VmaWriter *vmaw;
     ProxmoxBackupHandle *pbs;
     GList *di_list;
-    QemuRecMutex backup_mutex;
+    QemuMutex backup_mutex;
     CoMutex dump_callback_mutex;
 } backup_state;
 
 static void pvebackup_init(void)
 {
-    qemu_rec_mutex_init(&backup_state.stat.lock);
-    qemu_rec_mutex_init(&backup_state.backup_mutex);
+    qemu_mutex_init(&backup_state.stat.lock);
+    qemu_mutex_init(&backup_state.backup_mutex);
     qemu_co_mutex_init(&backup_state.dump_callback_mutex);
 }
 
@@ -91,26 +91,26 @@ lookup_active_block_job(PVEBackupDevInfo *di)
 
 static void pvebackup_propagate_error(Error *err)
 {
-    qemu_rec_mutex_lock(&backup_state.stat.lock);
+    qemu_mutex_lock(&backup_state.stat.lock);
     error_propagate(&backup_state.stat.error, err);
-    qemu_rec_mutex_unlock(&backup_state.stat.lock);
+    qemu_mutex_unlock(&backup_state.stat.lock);
 }
 
 static bool pvebackup_error_or_canceled(void)
 {
-    qemu_rec_mutex_lock(&backup_state.stat.lock);
+    qemu_mutex_lock(&backup_state.stat.lock);
     bool error_or_canceled = !!backup_state.stat.error;
-    qemu_rec_mutex_unlock(&backup_state.stat.lock);
+    qemu_mutex_unlock(&backup_state.stat.lock);
 
     return error_or_canceled;
 }
 
 static void pvebackup_add_transfered_bytes(size_t transferred, size_t zero_bytes)
 {
-    qemu_rec_mutex_lock(&backup_state.stat.lock);
+    qemu_mutex_lock(&backup_state.stat.lock);
     backup_state.stat.zero_bytes += zero_bytes;
     backup_state.stat.transferred += transferred;
-    qemu_rec_mutex_unlock(&backup_state.stat.lock);
+    qemu_mutex_unlock(&backup_state.stat.lock);
 }
 
 // This may get called from multiple coroutines in multiple io-threads
@@ -226,9 +226,9 @@ static void coroutine_fn pvebackup_co_cleanup(void *unused)
 {
     assert(qemu_in_coroutine());
 
-    qemu_rec_mutex_lock(&backup_state.stat.lock);
+    qemu_mutex_lock(&backup_state.stat.lock);
     backup_state.stat.end_time = time(NULL);
-    qemu_rec_mutex_unlock(&backup_state.stat.lock);
+    qemu_mutex_unlock(&backup_state.stat.lock);
 
     if (backup_state.vmaw) {
         Error *local_err = NULL;
@@ -284,7 +284,7 @@ static void pvebackup_complete_cb(void *opaque, int ret)
 
     PVEBackupDevInfo *di = opaque;
 
-    qemu_rec_mutex_lock(&backup_state.backup_mutex);
+    qemu_mutex_lock(&backup_state.backup_mutex);
 
     di->completed = true;
 
@@ -305,7 +305,7 @@ static void pvebackup_complete_cb(void *opaque, int ret)
 
     g_free(di);
 
-    qemu_rec_mutex_unlock(&backup_state.backup_mutex);
+    qemu_mutex_unlock(&backup_state.backup_mutex);
 
     pvebackup_run_next_job();
 }
@@ -318,7 +318,7 @@ static void pvebackup_cancel(void)
     error_setg(&cancel_err, "backup canceled");
     pvebackup_propagate_error(cancel_err);
 
-    qemu_rec_mutex_lock(&backup_state.backup_mutex);
+    qemu_mutex_lock(&backup_state.backup_mutex);
 
     if (backup_state.vmaw) {
         /* make sure vma writer does not block anymore */
@@ -329,13 +329,13 @@ static void pvebackup_cancel(void)
         proxmox_backup_abort(backup_state.pbs, "backup canceled");
     }
 
-    qemu_rec_mutex_unlock(&backup_state.backup_mutex);
+    qemu_mutex_unlock(&backup_state.backup_mutex);
 
     for(;;) {
 
         BlockJob *next_job = NULL;
 
-        qemu_rec_mutex_lock(&backup_state.backup_mutex);
+        qemu_mutex_lock(&backup_state.backup_mutex);
 
         GList *l = backup_state.di_list;
         while (l) {
@@ -349,7 +349,7 @@ static void pvebackup_cancel(void)
             }
         }
 
-        qemu_rec_mutex_unlock(&backup_state.backup_mutex);
+        qemu_mutex_unlock(&backup_state.backup_mutex);
 
         if (next_job) {
             AioContext *aio_context = next_job->job.aio_context;
@@ -423,7 +423,7 @@ static void pvebackup_run_next_job(void)
 {
     assert(!qemu_in_coroutine());
 
-    qemu_rec_mutex_lock(&backup_state.backup_mutex);
+    qemu_mutex_lock(&backup_state.backup_mutex);
 
     GList *l = backup_state.di_list;
     while (l) {
@@ -433,7 +433,7 @@ static void pvebackup_run_next_job(void)
         BlockJob *job = lookup_active_block_job(di);
 
         if (job) {
-            qemu_rec_mutex_unlock(&backup_state.backup_mutex);
+            qemu_mutex_unlock(&backup_state.backup_mutex);
 
             AioContext *aio_context = job->job.aio_context;
             aio_context_acquire(aio_context);
@@ -453,7 +453,7 @@ static void pvebackup_run_next_job(void)
 
     block_on_coroutine_fn(pvebackup_co_cleanup, NULL); // no more jobs, run cleanup
 
-    qemu_rec_mutex_unlock(&backup_state.backup_mutex);
+    qemu_mutex_unlock(&backup_state.backup_mutex);
 }
 
 static bool create_backup_jobs(void) {
@@ -778,7 +778,7 @@ static void coroutine_fn pvebackup_co_prepare(void *opaque)
     }
     /* initialize global backup_state now */
 
-    qemu_rec_mutex_lock(&backup_state.stat.lock);
+    qemu_mutex_lock(&backup_state.stat.lock);
 
     if (backup_state.stat.error) {
         error_free(backup_state.stat.error);
@@ -801,7 +801,7 @@ static void coroutine_fn pvebackup_co_prepare(void *opaque)
     backup_state.stat.transferred = 0;
     backup_state.stat.zero_bytes = 0;
 
-    qemu_rec_mutex_unlock(&backup_state.stat.lock);
+    qemu_mutex_unlock(&backup_state.stat.lock);
 
     backup_state.speed = (task->has_speed && task->speed > 0) ? task->speed : 0;
 
@@ -895,16 +895,16 @@ UuidInfo *qmp_backup(
         .errp = errp,
     };
 
-    qemu_rec_mutex_lock(&backup_state.backup_mutex);
+    qemu_mutex_lock(&backup_state.backup_mutex);
 
     block_on_coroutine_fn(pvebackup_co_prepare, &task);
 
     if (*errp == NULL) {
         create_backup_jobs();
-        qemu_rec_mutex_unlock(&backup_state.backup_mutex);
+        qemu_mutex_unlock(&backup_state.backup_mutex);
         pvebackup_run_next_job();
     } else {
-        qemu_rec_mutex_unlock(&backup_state.backup_mutex);
+        qemu_mutex_unlock(&backup_state.backup_mutex);
     }
 
     return task.result;
@@ -914,11 +914,11 @@ BackupStatus *qmp_query_backup(Error **errp)
 {
     BackupStatus *info = g_malloc0(sizeof(*info));
 
-    qemu_rec_mutex_lock(&backup_state.stat.lock);
+    qemu_mutex_lock(&backup_state.stat.lock);
 
     if (!backup_state.stat.start_time) {
         /* not started, return {} */
-        qemu_rec_mutex_unlock(&backup_state.stat.lock);
+        qemu_mutex_unlock(&backup_state.stat.lock);
         return info;
     }
 
@@ -955,7 +955,7 @@ BackupStatus *qmp_query_backup(Error **errp)
     info->has_transferred = true;
     info->transferred = backup_state.stat.transferred;
 
-    qemu_rec_mutex_unlock(&backup_state.stat.lock);
+    qemu_mutex_unlock(&backup_state.stat.lock);
 
     return info;
 }
